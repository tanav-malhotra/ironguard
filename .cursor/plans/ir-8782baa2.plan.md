<!-- 8782baa2-2fd0-45b6-a5cb-8460b749c66c 187d6aeb-b71c-4f46-999e-f0d5f05cd02d -->
# ironguard CLI + TUI + MCP – Implementation Plan

## 1. Project scaffolding and CLI entrypoint

- Set up a new Go module (e.g., `github.com/you/ironguard`) and initialize Git.
- Choose a small CLI framework or just Go `flag` such that `ironguard` runs the TUI by default (no subcommands), but supports `--help` and `--version` flags.
- Define a top-level configuration struct (in-memory only for v1) capturing: chosen AI provider (Claude/OpenAI/Gemini), model name, confirmation mode (autopilot vs confirm-everything), log level, and paths to your script directories.

## 2. TUI architecture (Claude Code–style)

- Use `bubbletea` + `bubbles` + `lipgloss` (or equivalent) to build a Claude Code–inspired layout:
- Main chat transcript pane (streaming assistant messages, user messages, and tool/action logs).
- Input panel for user text, with detection of `/` commands vs normal chat.
- Right/left sidebar pane showing current status (active task, queued actions, current provider/model, confirmation mode, and key toggles).
- Optional bottom status bar (hints, keybindings, and minimal telemetry like current MCP server connections).
- Implement a message-based internal model that can:
- Stream AI output token-by-token into the chat pane.
- Display tool calls and confirmations as structured messages (e.g., "AI wants to run: `sudo apt update`" with accept/deny keys).
- Handle interrupts (user messages that immediately preempt the current AI step) vs queued follow-ups (messages stored in a queue to run right after the current thought completes).

## 3. Chat input, slash commands, and autocomplete

- Implement an input mode that distinguishes between plain chat and slash commands beginning with `/`.
- Maintain a registry of commands (e.g., `/provider`, `/model`, `/confirm`, `/autopilot`, `/run-script`, `/list-scripts`, `/show-plan`, `/read-readme`, `/read-forensics`, `/help`, etc.).
- Build an autocomplete popup that appears when the user types `/` or continues typing a command name; show a scrollable, filterable list of known commands with short descriptions.
- Implement basic command handlers that mutate the in-memory config, trigger TUI events (like toggling confirmation mode), or kick off agent tasks (like "re-scan README" or "run hardening script X").

## 4. Multi-provider LLM abstraction (Claude, OpenAI, Gemini)

- Define a `LLMClient` interface with methods like `Complete` / `Chat` that support:
- Streaming responses (callback or channel-based API).
- Tool / function calling JSON schema (for agent-style workflows).
- Implement three concrete clients:
- `ClaudeClient` using Anthropic's API (e.g., Claude 3.5) with support for tool use.
- `OpenAIClient` targeting OpenAI-compatible APIs (OpenAI / Azure OpenAI) with `tools` / `function_call` support.
- `GeminiClient` using Google AI Studio Gemini API, including function calling if available.
- Read API keys from environment variables by default (e.g., `ANTHROPIC_API_KEY`, `OPENAI_API_KEY`, `GEMINI_API_KEY`), but allow setting or overriding them at runtime via a secure TUI prompt (kept in memory only for v1).
- Add a small provider registry and model presets per provider, so the user can quickly switch models with `/provider` and `/model` without touching config files.

## 5. Agent core and orchestration

- Build an `Agent` layer that sits between the TUI and the LLM client, responsible for:
- Maintaining conversation state (messages, tool calls, and high-level tasks).
- Translating provider-agnostic tool schemas into provider-specific `tools`/`functions` metadata.
- Handling tool call results and feeding them back into the LLM.
- Respecting confirmation mode: in "confirm" mode it pauses on any action that touches the system (commands, file writes, script calls) until the user approves via TUI.
- Implement agent operations for common flows:
- Initial onboarding task: read/parsing README from the current user’s Desktop, inspecting forensics folders, and proposing a prioritized plan for the image.
- Task loop: AI proposes next actions (e.g., run inspection scripts, harden system, search for vulnerabilities), the agent executes them via tools/MCP, and updates the TUI.
- Interrupt/queue behavior: if the user types during an ongoing action, allow them to either interrupt with a directive or queue a follow-up, controlled via a simple keystroke or `/queue` toggle.

## 6. Real MCP client integration

- Implement a minimal but spec-compliant MCP client in Go that can:
- Launch and manage one or more MCP servers as subprocesses (or connect over stdio / TCP, depending on the server).
- Perform the MCP handshake, list tools/resources, and invoke tools using JSON-RPC 2.0.
- Stream responses back to the agent/TUI, including partial outputs and errors.
- Create one or more dedicated MCP servers or adapt existing ones that expose exactly the capabilities you need:
- Files/resources: Desktop README, CyberPatriot forensics folders, log files, configuration files, etc.
- Tools: `read_file`, `list_dir`, `search_text`, `run_command`, `run_script`, `apply_hardening_step`, etc.
- In the agent, treat MCP tools as first-class tools alongside any built-in Go tools, so from the LLM’s point of view it just has a unified toolset; internally the agent routes calls either to MCP servers or local helpers.

## 7. CyberPatriot-specific tools and script integration

- Inventory your existing hardening/inspection scripts for both Windows and Linux (PowerShell, Batch, Bash, etc.) and categorize them (e.g., "baseline hardening", "service audit", "user audit", "patching", etc.).
- Implement a `ScriptRunner` abstraction that can:
- Discover available scripts from configured directories at runtime.
- Expose them to the LLM as tools via MCP or direct tool wrappers.
- Capture stdout/stderr and exit codes, streaming them back into the TUI.
- Replace file-based config tweaking with interactive TUI forms:
- When a script requires options, render a simple form (fields, checkboxes, select lists) in the TUI instead of editing config files manually.
- Pass form results as arguments/environment variables to the scripts.
- Add tailored tools for common CyberPatriot tasks (reading image README, parsing scoring reports if available, scanning for weak points) and ensure the AI has structured ways to call them.

## 8. Safety modes, confirmations, and observability

- Implement two primary modes:
- **Autopilot mode**: AI can run tools/commands/scripts automatically, but still logs all actions to the TUI.
- **Confirm mode**: any operation that mutates the system (e.g., file writes, registry edits, service changes, package installs) triggers a confirmation dialog in the TUI with a concise summary and, where possible, diffs of changes.
- Add clear visual indicators in the TUI for which mode is active (color theme, status bar text, or an icon).
- Provide `/dry-run` or preview-style commands where feasible so the AI can simulate plans or show diffs before applying hardening steps.
- Implement minimal structured logging (to a log file and/or scrollback buffer) so you have a record of what actions the AI took during a run, while keeping things simple enough for competition use.

## 9. UX polish and theming

- Design a clean color palette and component styling inspired by Claude Code: clear separation of panes, subtle borders, and readable typography.
- Add keyboard shortcuts for common operations (e.g., `Ctrl+N` new task, `Ctrl+L` clear screen, `Ctrl+/` show commands, `Tab` cycle suggestions, `Esc` close modals).
- Ensure the layout degrades gracefully on smaller terminal sizes common in competition VMs and works well on both Windows and Linux terminals.
- Provide a quick in-TUI help view (`/help` or `?`) summarizing commands, keybindings, and basic workflow.

## 10. Testing, CI, and documentation

- Write unit tests for:
- LLM provider clients (mocking HTTP).
- Core agent logic (tool routing, confirmation handling, interrupt/queue behavior).
- TUI model logic (state transitions and command handling, not the rendering itself).
- MCP client protocol handling and basic server interactions (with fake/test servers).
- Add basic integration tests that simulate a short end-to-end run with a fake LLM and fake MCP server, ensuring the agent can plan, call tools, and handle confirmations.
- Set up a minimal CI workflow (Go test + `go vet`) and ensure everything is race-free and cross-platform.
- Write a concise but clear `README.md` describing how to install the `ironguard` binary, set API keys, run it with no flags, and operate the TUI during a CyberPatriot round.

### To-dos

- [ ] Scaffold the Go module, Git repo, and basic `ironguard` CLI entrypoint with `--help` and `--version` flags that launches a placeholder TUI by default.
- [ ] Implement the Claude Code–inspired TUI layout (chat pane, input with slash commands, sidebar/status, and basic keybindings) using a Go TUI framework.
- [ ] Create the provider-agnostic LLM interface and concrete clients for Claude, OpenAI, and Gemini with streaming and tool/function-calling support.
- [ ] Build the agent layer that manages conversation state, tool calls, confirmation mode, and interrupt/queue behavior, wired into the TUI and LLM clients.
- [ ] Implement a minimal real MCP client in Go and integrate it so the agent can discover and invoke tools from one or more MCP servers.
- [ ] Integrate existing Windows/Linux CyberPatriot scripts via a ScriptRunner abstraction and replace config-file editing with TUI-based option forms.
- [ ] Implement autopilot vs confirm-everything modes with clear TUI indicators, confirmation dialogs, and logging of all mutating actions.
- [ ] Add unit/integration tests, a basic CI workflow, and a detailed README documenting usage, setup, and competition best practices for ironguard.